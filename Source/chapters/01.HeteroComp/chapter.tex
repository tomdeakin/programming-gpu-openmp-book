%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%  
%% Chapter 1: Introduction to heterogeneous computing
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\def\ArtDir{01.HeteroComp/figures}%

\chapter{Heterogeneity and the future of computing}
\label{chapter:heterogeneity}

\section{From The Next Step Chapter 6}

Specialized accelerator processors, which dramatically improve the performance
of some computations, are proliferating, and general-purpose processors are
now very often connected to some type of accelerator.  
The popularity of these heterogeneous architectures across all types of
computing has had a noticeable impact on the development of software.  

To exploit these systems, developers must write software that executes various
regions of code on different types of devices.  There are many reasons for
wanting to do this but very often the motivation is to accelerate
computationally intensive loop nests.  

However, the programming models for these systems are difficult to use.
Often code modules are written twice, once for the general-purpose
processor and then again for the accelerator.  The accelerator version is often
written in a lower-level, accelerator-specific language.  The result is the
undesirable software maintenance problem of keeping two versions of code, which
implement the same algorithm, synchronized.

The \OMP\ Language Committee recognized the need to make it easier to program
heterogeneous architectures and set about to extend \OMP\ to support these types
of systems \cite{Beyer2011}.  The results of this work were initially released
in \OMPfourzero\ and updated in \OMPfourfive.

Software developers can use \OMP\ to program accelerators in a higher-level
language and maintain one version of their code, which can run on either an
accelerator or a general-purpose processor.  In this chapter, we present the
syntax for and describe how to use the \OMP\ \emph{device constructs} and
related runtime functions that were added to support heterogeneous
architectures. 

%What was needed is a programming model that could...
%Given the popularity of heterogeneous systems across all types of computing,

%There is a place here for \OMP\ to make these software packages more
%maintainable and portable.  We hope that in the future, as the latest versions
%of \OMP\ are implemented in more compilers, software developers will leverage
%the \OMP\ device constructs and develop one version of their code that can run
%anywhere, including on accelerators.

%There is a place here for \OMP\ to make these software packages more
%maintainable and portable.  We hope that in the future, as the latest versions
%of \OMP\ are implemented in more compilers, 
\section{What is Heterogeneous computing and why everyone will be doing it}

\section{The basic building blocks of modern computing}

\begin{itemize}
\item Introduce a set of standard processors.
\item  the CPU: the multiprocessor and cache coherent memory
\item  the SIMD or Vector Unit: lock-step execution across vector lanes
\item  the GPU:  Index space, kernels, work-items and work-groups
\end{itemize}

\subsection{Introduce Cache coherent shared memory machine. SMP model.}
Introduce what a standard CPU looks like. This is the host processor.

\subsection{Introduce GPU model}
Describe an abstract vendor-neutral GPU.
Using terms/definitions from OpenCL make this convenient.
Local memory, will use in Chapter~\ref{chapter:portable}.

In the book we will describe programming this GPU in OpenMP.
Later, we include case studies of how this applies to real hardware.


\section{Why you need OpenMP: a single code-base for heterogeneous hardware}

\section{Templates for use in formatting the rest of the book.}

Here is how we handle a code fragment embedded in text.
Consider a simple program that adds two vectors, \code{a} and \code{b}.
\begin{verbatim}
      for (i = 0; i < N; i++) { 
         a[i] = a[i] + b[i];
      }
\end{verbatim}  

For longer code fragments, we put the code in a proper figure.  For example, consider figure~\ref{code:vaddSPMD}

\begin{CodeExample}%
{\textbf{SPMD parallel vector add program} -- \small
Create a team of threads and assign one chunk of loop iterations
to each thread.
}%
{code:vaddSPMD}
\begin{lstlisting}
// OpenMP parallel region and SPMD pattern
#pragma omp parallel
{
   int id, i, Nthrds, istart, iend;
   id = omp_get_thread_num();
   Nthrds = omp_get_num_threads(); 
   istart = id * N / Nthrds;
   iend = (id + 1) * N / Nthrds;
   if (id == Nthrds - 1) iend = N; 
   for (i = istart; i < iend; i++) {
      a[i] = a[i] + b[i];
   }
}
\end{lstlisting}
\end{CodeExample} 



When we have specific constructs to introduce, we use a table with marcros for the constructs themselves.  This way we can make 
sure that we use consistent fonts and styles across the entire book.  Take a look at table~\ref{tab:omp_for} for a good example.

\begin{table}[!htbp]
\centering
\caption{\textbf{A basic worksharing-loop construct in C/C++ and Fortran} 
-- \small
The worksharing-loop construct shares the iterations of a loop among
a team of threads.  The loop is called \texttt{for} in C and \texttt{DO} in Fortran.
Fortran is not block structured, so we need an \texttt{END DO} directive.
Optional clauses give the programmer more control
over the loop construct and include \texttt{schedule}, \texttt{reduction}, and 
\texttt{nowait}. We will discuss these clauses later in this chapter.  Additional clauses define storage attributes 
of the variables used in the worksharing-loop.  We will cover those in 
Chapter~\ref{ch:dataEnv}.  
}
\label{tab:omp_for}
\begin{tabular}{|l|} \hline
\ompbcfor \ompclauses \\ 
%\hspace{5mm} \{   \\
\hspace{5mm} for-loop \\      
%\hspace{5mm} \}    \\           
\hline
\ompbfdo \ompclauses  \\ 
%\hspace{5mm} \{   \\
\hspace{5mm} do-loop   \\
%\hspace{5mm} \}   \\ 
\ompbfdoend \textit{ [nowait] } \\   
                  
\hline

\end{tabular}
\end{table}

Here is an index entry:  Moore's law\index{Moore's law} and a citation Dennard scaling\index{Dennard scaling}~\cite{Dennard}, 


There are some open questions concerning what we need to cover.
\begin{itemize}
\item Do we need to include \code{declare simd}?  Is that enabled for a GPU?  
\item Do we need to discuss the variant directives?  If they are 
important for GPU programmers, then we probably need to. Likewise for assumes and assume.  
\item Does the scan directive apply to GPUs?  
\item Does tile and unroll apply to GPUs?  
\item Do memory spaces apply to GPUs?
\end{itemize}

We will also need to cover a set of internal control variables and where appropriate a set of environment variables.

\begin{table}[h!]
\centering
\caption{All the pragmas we will cover in the book and the chapters where we will cover them}
\label{YourLabel}
\input{\ArtDir/ompGPUpragmas.tex}
 \end{table}

\begin{table}[h!]
\centering
\caption{All the clauses we will cover in the book and the chapters where we will cover them}
\label{YourLabel}
\input{\ArtDir/ompGPUclauses.tex}
 \end{table}
 
\begin{table}[h!]
\centering
\caption{All the runtime functions we will cover in the book and the chapters where we will cover them}
\label{YourLabel}
\input{\ArtDir/ompGPUfuncs.tex}
 \end{table}
 
\begin{table}[h!]
\centering
\caption{All the internal control variables and associated environment variables we will 
cover in the book and the chapters where we will cover them}
\label{YourLabel}
\input{\ArtDir/ompGPUicvEnvVar.tex}
 \end{table}


